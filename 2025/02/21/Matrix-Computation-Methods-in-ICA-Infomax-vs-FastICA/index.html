<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Theory and ConceptInfomax ICA (Infomation maximization independent Component Analysis) is one of the main algorithms for Blind Source Separation(BSS). This algorithm is able to separate independent so">
<meta property="og:type" content="article">
<meta property="og:title" content="Matrix Methods in ICA: Infomax vs. FastICA">
<meta property="og:url" content="http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/index.html">
<meta property="og:site_name" content="Elvin&#39;s Blog">
<meta property="og:description" content="Theory and ConceptInfomax ICA (Infomation maximization independent Component Analysis) is one of the main algorithms for Blind Source Separation(BSS). This algorithm is able to separate independent so">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-02-21T20:23:50.000Z">
<meta property="article:modified_time" content="2025-09-01T12:00:42.954Z">
<meta property="article:tag" content="Algorithm">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>Matrix Methods in ICA: Infomax vs. FastICA</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>

<body class="ltr">
    <div class="page-container">
  
            
                <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/#side-projects">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2025/02/25/Some-Questions-about-Mechine-Learning/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2025/02/19/Matrix-Computation-Algorithms/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&text=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&is_video=false&description=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Matrix Methods in ICA: Infomax vs. FastICA&body=Check out this article: http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&name=Matrix Methods in ICA: Infomax vs. FastICA&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&t=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Theory-and-Concept"><span class="toc-number">1.</span> <span class="toc-text">Theory and Concept</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Blind-Source-Separation"><span class="toc-number">1.1.</span> <span class="toc-text">Blind Source Separation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shannon-Entropy"><span class="toc-number">1.2.</span> <span class="toc-text">Shannon Entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mutual-Information-and-Minimization"><span class="toc-number">1.3.</span> <span class="toc-text">Mutual Information and Minimization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Principle-of-Infomax-ICA-Method"><span class="toc-number">1.4.</span> <span class="toc-text">The Principle of Infomax ICA Method</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Algorithm"><span class="toc-number">2.</span> <span class="toc-text">Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Infomax-ICA"><span class="toc-number">2.1.</span> <span class="toc-text">Infomax ICA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Steepest-Descent"><span class="toc-number">2.1.1.</span> <span class="toc-text">Steepest Descent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FastICA"><span class="toc-number">2.2.</span> <span class="toc-text">FastICA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Experiment"><span class="toc-number">3.</span> <span class="toc-text">Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Computation-time"><span class="toc-number">3.1.</span> <span class="toc-text">Computation time</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Independent-Component-Analysis-Evaluation"><span class="toc-number">3.2.</span> <span class="toc-text">Independent Component Analysis Evaluation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convergence-speed"><span class="toc-number">3.3.</span> <span class="toc-text">Convergence speed</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Related-Papers-and-Books"><span class="toc-number">5.</span> <span class="toc-text">Related Papers and Books</span></a></li></ol>
      </div>
    
  </span>
</div>

            
            <div class="content index py4 ">
                
                <div class="main-container">
                    <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        Matrix Methods in ICA: Infomax vs. FastICA
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name"></span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2025-02-21T20:23:50.000Z" class="dt-published" itemprop="datePublished">2025-02-21</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/Algorithm/" rel="tag">Algorithm</a>, <a class="p-category" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="Theory-and-Concept"><a href="#Theory-and-Concept" class="headerlink" title="Theory and Concept"></a>Theory and Concept</h1><p>Infomax ICA (Infomation maximization independent Component Analysis) is one of the main algorithms for Blind Source Separation(BSS). This algorithm is able to separate independent source signals from EEG data and is widely used for artifact removal such as EOG, EMG, and ECG artifacts as well as neural signal component analysis.</p>
<h2 id="Blind-Source-Separation"><a href="#Blind-Source-Separation" class="headerlink" title="Blind Source Separation"></a>Blind Source Separation</h2><p>EEG recorded signals linear mixed by several independent source signals:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mi>A</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">X=AS</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<p>which</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>m</mi><mo>∗</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X \in R^{m*n} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>: EEG observed signal matrix (m channels, n time points)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>m</mi><mo>∗</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A \in R^{m*m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span>: unmixing matrix (unknown)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>m</mi><mo>∗</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">S \in R^{m*n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>: independent signal sources</li>
</ul>
<p>Target of ICA is find unmixing matrix, such that</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mi>W</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">S=WX</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>
<p>Thus the independent components are recovered.</p>
<h2 id="Shannon-Entropy"><a href="#Shannon-Entropy" class="headerlink" title="Shannon Entropy"></a>Shannon Entropy</h2><p>Entropy measures the uncertainty of a random variable and is defined as</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mo>∑</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(X) = - \sum p(x)\log p(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>

<p>Intuitivly, entropy is maximized if all events are equally likely. If the probability of some event is close to 1 (high certainty), entropy is minimal.</p>
<h2 id="Mutual-Information-and-Minimization"><a href="#Mutual-Information-and-Minimization" class="headerlink" title="Mutual Information and Minimization"></a>Mutual Information and Minimization</h2><p>I(X;Y) &#x3D; H(X) + H(Y) - H(X,Y)<br>Mutual information measure the dependency between two variables.</p>
<p>The goal of Infomax ICA is to find a nonlinear transformation such that the mutual information of the output signal is minimized, such that the components are as independent as possible.</p>
<p>Definition of Mutual Infomation:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><msub><mi>S</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>S</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>S</mi><mi>m</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo>∑</mo><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msup><mi>H</mi><mo stretchy="false">(</mo><msub><mi>S</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>H</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(S_1, S_2,...,S_m) = \sum \limits{i=1}^m H(S_i) - H(S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7138em;"><span style="top:-3.1124em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span> 
<p>Which H(S) is the entropy of the signal:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mo>∫</mo><mi>p</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mi>d</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">H(S) = - \int p(S) \log p(S) dS</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.3061em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0006em;">∫</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>

<p>In order to maximize the entropy of the independent components, Infomax ICA uses gradient descent optimization ofn neural networks to adjust the weight matrix W, so that the probability distribution of the output signals is close to the maximum entropy.</p>
<h2 id="The-Principle-of-Infomax-ICA-Method"><a href="#The-Principle-of-Infomax-ICA-Method" class="headerlink" title="The Principle of Infomax ICA Method"></a>The Principle of Infomax ICA Method</h2><p>Infomax ICA tries to find a nonlinear transformation that maximizes the entropy of the separated signals, resulting in the most independent signals.</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><mi mathvariant="normal">arg max</mi><mo>⁡</mo><mi>H</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">arg max</mi><mo>⁡</mo><mi>H</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>W</mi><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W= \argmax H(Y) = \argmax H(g(WX))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">arg</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">max</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">arg</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">max</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">))</span></span></span></span>
<p>which </p>
<ul>
<li>X is observed signal</li>
<li>W is unmixing matrix</li>
<li>g(·) is activation function (sigmoid or tanh)</li>
</ul>
<p>Key of Informax ICA:</p>
<ol>
<li>Select proper nonlinear function g, e.g. sigmoid.</li>
<li>Optimization using gradient descent.</li>
<li>The entropy of the output signal is maximized.</li>
</ol>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h1><h2 id="Infomax-ICA"><a href="#Infomax-ICA" class="headerlink" title="Infomax ICA"></a>Infomax ICA</h2><p>Assuming the observed signal is X, the source signal is S, then:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mi>A</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">X= AS</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<p>which </p>
<ul>
<li>A is the mixing matrix</li>
</ul>
<p>Our target is to find the unmixing matrix W:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>W</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">Y= WX</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>
<p>to make Y as Independent as possible.</p>
<p>Infomax ICA algorithm optimize unmixing matrix W through maxmizing the output signal entropy, which is solved by gradient descent, the update rule is :</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msup><mo>+</mo><mi>η</mi><mo stretchy="false">(</mo><mi>I</mi><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>2</mn><mi>Y</mi><mo stretchy="false">)</mo><msup><mi>Y</mi><mi>T</mi></msup><mo stretchy="false">)</mo><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">W^{(t+1)} = W^{(t)} + \eta (I + (1-2Y)Y^T)W^{(t)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9713em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>
<p>This formular is a variant of <strong>Steepest Descent</strong>, which</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>2</mn><mi>Y</mi><mo stretchy="false">)</mo><msup><mi>Y</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">I + (1-2Y)Y^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> is gradient term ( gradients derived from information theory )</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span> is learning rate, control the update step.
Since it is only updated in the gradient direction and does not use second-order information( such as the Hessian matrix), it strictly falls into the category of steepest descent methods.</li>
</ul>
<h3 id="Steepest-Descent"><a href="#Steepest-Descent" class="headerlink" title="Steepest Descent"></a>Steepest Descent</h3><p>Steepest descent is the most basic gradient descent method, its update formula is:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msup><mo>−</mo><mi>η</mi><mi mathvariant="normal">Δ</mi><mi>f</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W^{(t+1)} = W^{(t)} - \eta \Delta f(W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9713em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span>
<p>which</p>
<ul>
<li>W is the parameter to optimize (unmixing matrix in ICA)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span> is learning rate (step size)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>f</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Delta f(W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span> is the gradient direction of the objective function, which indicates the direction of the current fastest descent.
The core idea of the steepest descent method is to take a small step in the direction of the gradient and gradually approach the optimal solution.</li>
</ul>
<h2 id="FastICA"><a href="#FastICA" class="headerlink" title="FastICA"></a>FastICA</h2><h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><h2 id="Computation-time"><a href="#Computation-time" class="headerlink" title="Computation time"></a>Computation time</h2><h2 id="Independent-Component-Analysis-Evaluation"><a href="#Independent-Component-Analysis-Evaluation" class="headerlink" title="Independent Component Analysis Evaluation"></a>Independent Component Analysis Evaluation</h2><h2 id="Convergence-speed"><a href="#Convergence-speed" class="headerlink" title="Convergence speed"></a>Convergence speed</h2><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><h1 id="Related-Papers-and-Books"><a href="#Related-Papers-and-Books" class="headerlink" title="Related Papers and Books"></a>Related Papers and Books</h1><ol>
<li><p>Bell, A. J., &amp; Sejnowski, T. J. (1995). An Information-Maximization Approach to Blind Separation and Blind Deconvolution. (DOI: 10.1162&#x2F;neco.1995.7.6.1129)</p>
<ul>
<li>This is the fundamental paper of Infomax ICA, proposed by Bell and Sejnowski.</li>
<li>This paper introduced how to seperate independent signals through maximize mutual information</li>
<li>Proposed weights updating method based on gradient descent, and performed it in blind source seperation</li>
</ul>
</li>
<li><p>Makeig, S., Jung, T. P., Bell, A. J., Ghahremani, D., &amp; Sejnowski, T. J. (1997). Blind separation of auditory event-related brain responses into independent components.(DOI: 10.1073&#x2F;pnas.94.20.10979)</p>
<ul>
<li>this paper detailly introduced the application of Infomax ICA in EEG analysis</li>
<li>Introduced how to seperate EEG with ICA, and remove artifact signals such as EOG, EMG </li>
<li>proposed Extended Infomax ICA, to process Sub-Gaussian and Super-Gaussian signals</li>
</ul>
</li>
</ol>

  </div>
</article>



                </div>
                
                    <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/#side-projects">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Theory-and-Concept"><span class="toc-number">1.</span> <span class="toc-text">Theory and Concept</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Blind-Source-Separation"><span class="toc-number">1.1.</span> <span class="toc-text">Blind Source Separation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shannon-Entropy"><span class="toc-number">1.2.</span> <span class="toc-text">Shannon Entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mutual-Information-and-Minimization"><span class="toc-number">1.3.</span> <span class="toc-text">Mutual Information and Minimization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Principle-of-Infomax-ICA-Method"><span class="toc-number">1.4.</span> <span class="toc-text">The Principle of Infomax ICA Method</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Algorithm"><span class="toc-number">2.</span> <span class="toc-text">Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Infomax-ICA"><span class="toc-number">2.1.</span> <span class="toc-text">Infomax ICA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Steepest-Descent"><span class="toc-number">2.1.1.</span> <span class="toc-text">Steepest Descent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FastICA"><span class="toc-number">2.2.</span> <span class="toc-text">FastICA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Experiment"><span class="toc-number">3.</span> <span class="toc-text">Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Computation-time"><span class="toc-number">3.1.</span> <span class="toc-text">Computation time</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Independent-Component-Analysis-Evaluation"><span class="toc-number">3.2.</span> <span class="toc-text">Independent Component Analysis Evaluation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convergence-speed"><span class="toc-number">3.3.</span> <span class="toc-text">Convergence speed</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Related-Papers-and-Books"><span class="toc-number">5.</span> <span class="toc-text">Related Papers and Books</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&text=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&is_video=false&description=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Matrix Methods in ICA: Infomax vs. FastICA&body=Check out this article: http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&title=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&name=Matrix Methods in ICA: Infomax vs. FastICA&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2025/02/21/Matrix-Computation-Methods-in-ICA-Infomax-vs-FastICA/&t=Matrix Methods in ICA: Infomax vs. FastICA"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

                 
                   
                        
                    
                 <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2025
    Elvin&#39;s Blog
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/#side-projects">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

            </div>

                 


        </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>

<style>
      .side-iframe{
                            height: 100vh;
                            width: 100vw;
                            overflow: visible !important;
                          }
    html{
        scrollbar-width: none; /* 'auto' | 'thin' | 'none' */
    }
body{
    scrollbar-width: none; /* 'auto' | 'thin' | 'none' */
}
.page-container {
    display: grid;
    width: 100%;
    min-height: fit-content;
    transition: grid-template-columns 0.3s ease;

    margin: 0 auto;
    padding: 1rem;
    display: flex;
    flex-direction: column;
    align-items: center;
    scrollbar-width: none; /* 'auto' | 'thin' | 'none' */
}

.content {
    width: 800px;
    margin: 0 auto;
    padding: 0;
    display: flex;
    flex-direction: column;
    align-items: left;
    scrollbar-width: none; /* 'auto' | 'thin' | 'none' */

}

.main-container {
    width: 100%;
    max-width: 100%;
    margin: 1rem;
    padding: 1rem;
    margin-bottom: 5rem;
}

.header-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    width: 800px;
    padding: 1rem;
}

/* Large screens */
@media (min-width: 1200px) {
    .page-container {
        grid-template-columns: 1fr 1fr;
    }
}

/* Medium screens */
@media (max-width: 1199px) and (min-width: 769px) {
    .page-container {
        grid-template-columns: 45% 55%;
    }
}

/* Small screens */
@media (max-width: 768px) {
    .page-container {
        grid-template-columns: 1fr;
        height: auto;
    }
    
    .content-side,
    .resume-side {
        width: 100%;
        height: 100vh;
    }

    .resume-side {
        position: relative;
    }

    .content {
        padding: 1rem;
    }
}

/* Extra small screens */
@media (max-width: 480px) {
    .content-side {
        padding: 0.5rem;
    }
}
</style>
